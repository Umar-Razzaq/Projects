{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "dm_spring_2021_assignment2_q2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js-DcwwJemGW"
      },
      "source": [
        "# Question 2 [25 Marks]\n",
        "\n",
        "1. In this part, you are required to implement Apriori and FPgrowth algorithms on the data provided as \"data_apriori_fpgrowth/data.csv\". The dataset is of online directory of certified businesses.\n",
        "\n",
        "2. We have loaded the dataset for you.\n",
        "\n",
        "3. **You are free to use any library or implement your own algorithms**.\n",
        "\n",
        "\n",
        "**Use minimum support : 0.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMHIxXQmemGd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9uojllbemGh"
      },
      "source": [
        "data_rows = np.load(\"/content/data.npy\", allow_pickle = True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omY4-XFym2EX",
        "outputId": "7b362206-2d88-4f8e-b0e0-c0f36760b198"
      },
      "source": [
        "data_rows"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['MBE', 'WBE', 'BLACK', 'Cambria Heights', '11411']),\n",
              "       list(['LBE', 'Brooklyn', '11204']),\n",
              "       list(['MBE', 'BLACK', 'Yorktown Heights', '10598']), ...,\n",
              "       list(['MBE', 'BLACK', 'Brooklyn', '11214']),\n",
              "       list(['LBE', 'New York', '10016']),\n",
              "       list(['MBE', 'ASIAN', 'New York', '10002'])], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNlgXLueemGh"
      },
      "source": [
        "# To Do\n",
        "1. Run Apriori Algorithm on the dataset using minimum support 0.1.\n",
        " 1. Note the run time of the algorithm to find frequent item sets.\n",
        " 1. Print all the frequent item sets found by apriori.\n",
        " 1. Print all frequent item sets of length $2$ or higher with support of $0.2$ or higher. \n",
        "1. Run FPGrowth Algorithm on the dataset using minimum support 0.1.\n",
        " 1. Note the run time of the FPGrowth algorithm to find frequent item sets.\n",
        " 1. Print all frequent item sets found by FPGrowth.\n",
        " 1. Print all frequent item sets of length $2$ or higher with support of $0.2$ or higher.\n",
        "1. Answer the following question:\n",
        " 1. Both algorithms find and return exactly the same frequent itemsets (given same parameters of support and itemset length). What difference do you note in both of the algorithms?\n",
        " 1. There were more than $1000$ transactions. Why there are too few itemsets returned by the algorithms?\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrb-kMqMnVwh",
        "outputId": "82b7f12c-c97b-49c3-f02f-d7fa61f9d8c4"
      },
      "source": [
        "!pip install apyori\r\n",
        "!pip install pyfpgrowth"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: apyori in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Collecting pyfpgrowth\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/4c/8b7cd90b4118ff0286d6584909b99e1ca5642bdc9072fa5a8dd361c864a0/pyfpgrowth-1.0.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 5.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyfpgrowth\n",
            "  Building wheel for pyfpgrowth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfpgrowth: filename=pyfpgrowth-1.0-py2.py3-none-any.whl size=5477 sha256=b5cd1525501826d117876f8e6b33af5144a9a6376a81e71ab936271afbd690d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/3f/0d/a04bb8b17887c1eca7d0f1a48d4aa0c09c96eb221ff7fa56c1\n",
            "Successfully built pyfpgrowth\n",
            "Installing collected packages: pyfpgrowth\n",
            "Successfully installed pyfpgrowth-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us-WUx4CnHMo"
      },
      "source": [
        "import apyori\r\n",
        "import pyfpgrowth"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xIMrjCAemGh"
      },
      "source": [
        "# Apriori [10 marks]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urzi5L5CemGi",
        "outputId": "fea49ddd-d76c-431d-c092-11e94fe58145"
      },
      "source": [
        "# Apriori\r\n",
        "%%time\r\n",
        "ap_results=list(apyori.apriori(data_rows,min_support=0.1))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.22 ms, sys: 1.04 ms, total: 8.26 ms\n",
            "Wall time: 9.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4mxmmBGemGi",
        "outputId": "ab3ccb43-fe2e-4731-d47c-a476cf37be68"
      },
      "source": [
        "# All Frequent Itemsets\r\n",
        "print('Total items are:',len(ap_results))\r\n",
        "for i in ap_results:\r\n",
        "    print(i[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total items are: 18\n",
            "frozenset({'ASIAN'})\n",
            "frozenset({'BLACK'})\n",
            "frozenset({'Brooklyn'})\n",
            "frozenset({'HISPANIC'})\n",
            "frozenset({'MBE'})\n",
            "frozenset({'NON-MINORITY'})\n",
            "frozenset({'New York'})\n",
            "frozenset({'WBE'})\n",
            "frozenset({'MBE', 'ASIAN'})\n",
            "frozenset({'MBE', 'BLACK'})\n",
            "frozenset({'MBE', 'Brooklyn'})\n",
            "frozenset({'MBE', 'HISPANIC'})\n",
            "frozenset({'MBE', 'New York'})\n",
            "frozenset({'MBE', 'WBE'})\n",
            "frozenset({'NON-MINORITY', 'New York'})\n",
            "frozenset({'WBE', 'NON-MINORITY'})\n",
            "frozenset({'WBE', 'New York'})\n",
            "frozenset({'WBE', 'NON-MINORITY', 'New York'})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frCNQO0QemGi",
        "outputId": "f95eea5c-1132-489a-8ec6-ba8b51c63c5f"
      },
      "source": [
        "# Frequent itemsets of length 2 with support of 0.1\r\n",
        "ap_results_2 = list(apyori.apriori(data_rows,min_support=0.2,min_length=2))\r\n",
        "print('Total items are:',len(ap_results_2))\r\n",
        "for x in ap_results_2:\r\n",
        "    if len(x[0]) >= 2:\r\n",
        "        print(x[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total items are: 9\n",
            "frozenset({'MBE', 'ASIAN'})\n",
            "frozenset({'MBE', 'BLACK'})\n",
            "frozenset({'WBE', 'NON-MINORITY'})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OlZmf3IemGi"
      },
      "source": [
        "# FPGrowth [10 marks]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMEdDDwnemGj",
        "outputId": "a7058460-9b9d-48cf-dbf5-0fc8c2e9e1c5"
      },
      "source": [
        "%%time\r\n",
        "# FPGrowth\r\n",
        "d = 0.1*len(data_rows)\r\n",
        "fp_results = list(pyfpgrowth.find_frequent_patterns(data_rows,d))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12.5 ms, sys: 42 µs, total: 12.5 ms\n",
            "Wall time: 18.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sX0Hfh_emGj",
        "outputId": "5434226d-35aa-4327-fff6-2da24d8034ed"
      },
      "source": [
        "# All Frequent Itemsets\r\n",
        "print('Total items are:',len(fp_results))\r\n",
        "for x in fp_results:\r\n",
        "    print(x)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total items are: 17\n",
            "('Brooklyn',)\n",
            "('Brooklyn', 'MBE')\n",
            "('HISPANIC',)\n",
            "('HISPANIC', 'MBE')\n",
            "('ASIAN',)\n",
            "('ASIAN', 'MBE')\n",
            "('NON-MINORITY', 'New York')\n",
            "('NON-MINORITY', 'New York', 'WBE')\n",
            "('MBE', 'New York')\n",
            "('New York', 'WBE')\n",
            "('NON-MINORITY',)\n",
            "('NON-MINORITY', 'WBE')\n",
            "('BLACK',)\n",
            "('BLACK', 'MBE')\n",
            "('WBE',)\n",
            "('MBE', 'WBE')\n",
            "('MBE',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ9PdhJhemGj",
        "outputId": "ab26f250-09ad-4e88-f7e5-cf23f501c8ba"
      },
      "source": [
        "# Frequent itemsets of length 2 with support of 0.1\r\n",
        "d2 = 0.2*len(data_rows)\r\n",
        "fp_results_2 = list(pyfpgrowth.find_frequent_patterns(data_rows,d2))\r\n",
        "for x in fp_results_2:\r\n",
        "    if len(x) >=2:\r\n",
        "        print(x)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('ASIAN', 'MBE')\n",
            "('NON-MINORITY', 'WBE')\n",
            "('BLACK', 'MBE')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yy60ybgemGj"
      },
      "source": [
        "# Answer to the Questions [5 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adzULRtgemGk"
      },
      "source": [
        "#### Both algorithms find and return exactly the same frequent itemsets (given same parameters of support and itemset length). What difference do you note in both of the algorithms?\n",
        "\n",
        "##### Answer:\n",
        "Diffrences:\n",
        "1. fpgrowth takes longer time than Apriori.\n",
        "2. fpgrowth has returned one less itemset than Apriori."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0G2ZQLemGk"
      },
      "source": [
        "#### There were more than  1000  transactions. Why there are too few itemsets returned by the algorithms?\n",
        "##### Answer:\n",
        "This is because the support is 0.1, which means only the transactions that are part of more than 10% of the total transactions will be returned. That is a very high threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S67ssG1HemGk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}